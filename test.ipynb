{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 15:16:09.341194: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-10 15:16:09.342547: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 15:16:09.368914: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-10 15:16:09.369592: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-10 15:16:09.825826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/rikab/Documents/Research/MomentAnalysis/energyflow/archs/__init__.py:30: UserWarning: could not import some architectures - cannot import name 'cnn' from partially initialized module 'energyflow.archs' (most likely due to a circular import) (/home/rikab/Documents/Research/MomentAnalysis/energyflow/archs/__init__.py)\n",
      "  warnings.warn('could not import some architectures - ' + str(e))\n",
      "/home/rikab/Documents/Research/MomentAnalysis/energyflow/archs/__init__.py:40: UserWarning: could not import some architectures - cannot import name 'linear' from partially initialized module 'energyflow.archs' (most likely due to a circular import) (/home/rikab/Documents/Research/MomentAnalysis/energyflow/archs/__init__.py)\n",
      "  warnings.warn('could not import some architectures - ' + str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "from energyflow.archs.moment import EFN_moment, PFN_moment\n",
    "from energyflow.archs.moment_layers import Moment\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils.data_utils import load_data\n",
    "try:\n",
    "    from config import base_dir\n",
    "except:\n",
    "    raise ValueError(\"Please specify a base analysis directory, base_dir, in config.py!\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off TEST_MODE to run on full dataset\n",
    "TEST_MODE = True\n",
    "\n",
    "# Parameters \n",
    "train = 1000\n",
    "val = 5000\n",
    "test = 5000\n",
    "is_EFN = True\n",
    "categorical = False\n",
    "dataset = \"qg\"\n",
    "\n",
    "# Load data\n",
    "(X_train, X_val, X_test,), (Y_train, Y_val, Y_test,) = load_data(dataset, train, val, test, \n",
    "                                                                 EFN_format=is_EFN, \n",
    "                                                                 categorical=categorical)\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 2)]    0           []                               \n",
      "                                                                                                  \n",
      " tdist0_0 (TimeDistributed)     (None, None, 25)     75          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, 25)     0           ['tdist0_0[0][0]']               \n",
      "                                                                                                  \n",
      " tdist0_1 (TimeDistributed)     (None, None, 25)     650         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, 25)     0           ['tdist0_1[0][0]']               \n",
      "                                                                                                  \n",
      " tdist0_2 (TimeDistributed)     (None, None, 1)      26          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, 1)      0           ['tdist0_2[0][0]']               \n",
      "                                                                                                  \n",
      " zs_input (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)       (None, None, 1)      0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " mask (Lambda)                  (None, None)         0           ['zs_input[0][0]']               \n",
      "                                                                                                  \n",
      " moment_1 (Moment)              (None, None, 2)      0           ['tf.identity[0][0]']            \n",
      "                                                                                                  \n",
      " sum (Dot)                      (None, 2)            0           ['mask[0][0]',                   \n",
      "                                                                  'moment_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 25)           75          ['sum[0][0]']                    \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 25)           0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           650         ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 25)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 25)           650         ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 25)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 1)            26          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 1)            0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,152\n",
      "Trainable params: 2,152\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('Data/test/order_1/Models/O1_L1_2Phi25_3F25_0.keras', custom_objects={'Moment': Moment})\n",
    "\n",
    "# Show the model architecture\n",
    "new_model.summary()\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/rikab/Documents/Research/MomentAnalysis/test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rikab/Documents/Research/MomentAnalysis/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m dataset \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mqg\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rikab/Documents/Research/MomentAnalysis/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     X, Y \u001b[39m=\u001b[39m qg_jets\u001b[39m.\u001b[39mload(train\u001b[39m+\u001b[39mval\u001b[39m+\u001b[39mtest, cache_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/n/holyscratch01/iaifi_lab/rikab/.energyflow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rikab/Documents/Research/MomentAnalysis/test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     X \u001b[39m=\u001b[39m X[:,:,:\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "if dataset == \"qg\":\n",
    "    X, Y = qg_jets.load(train+val+test, cache_dir=\"/n/holyscratch01/iaifi_lab/rikab/.energyflow\")\n",
    "    X = X[:,:,:3].astype(np.float32)\n",
    "    for x in X:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "\n",
    "\n",
    "    Y = to_categorical(Y, num_classes=2)\n",
    "\n",
    "    (z_train, z_val, z_test,\n",
    "    p_train, p_val, p_test,\n",
    "    Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val, test=test)\n",
    "\n",
    "    X_train = [z_train, p_train]\n",
    "    X_val = [z_val, p_val]\n",
    "    X_test = [z_test, p_test]\n",
    "\n",
    "elif dataset == \"top\":\n",
    "    X_train, Y_train = toploader.load(cache_dir=topdir, dataset=\"train\", num_data = train)\n",
    "    X_test, Y_test = toploader.load(cache_dir=topdir, dataset=\"test\", num_data=test)\n",
    "    X_val, Y_val = toploader.load(cache_dir=topdir, dataset=\"val\", num_data=test)\n",
    "\n",
    "    def format(X):\n",
    "\n",
    "        for x in X:\n",
    "            mask = x[:,0] > 0\n",
    "            yphi_avg = average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "            x[mask,1:3] -= yphi_avg\n",
    "            x[mask,0] /= x[:,0].sum()\n",
    "\n",
    "        return [X[:,:,0], X[:,:,1:3]]\n",
    "    \n",
    "    X_train = format(X_train)\n",
    "    X_test = format(X_test)\n",
    "    X_val = format(X_val)\n",
    "\n",
    "    Y_train = to_categorical(Y_train, num_classes=2)\n",
    "    Y_test = to_categorical(Y_test, num_classes=2)\n",
    "    Y_val = to_categorical(Y_val, num_classes=2)\n",
    "\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"dataset must be either `top` or `qg`!\")\n",
    "\n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 100 1\n",
      "\n",
      "7 1 31102\n",
      "\n",
      "Epoch 1/5\n",
      "1/1 - 3s - loss: 0.7523 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7009 - val_acc: 0.5034 - val_auc_2: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.7018 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6952 - val_acc: 0.4966 - val_auc_2: 0.5000 - 714ms/epoch - 714ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.6949 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7075 - val_acc: 0.4966 - val_auc_2: 0.5000 - 713ms/epoch - 713ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.7064 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7133 - val_acc: 0.4966 - val_auc_2: 0.5000 - 1s/epoch - 1s/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.7120 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7097 - val_acc: 0.4966 - val_auc_2: 0.5000 - 1s/epoch - 1s/step\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/5\n",
      "1/1 - 2s - loss: 0.8181 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7566 - val_acc: 0.4966 - val_auc_2: 0.5000 - 2s/epoch - 2s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.7542 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7144 - val_acc: 0.4966 - val_auc_2: 0.5000 - 784ms/epoch - 784ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.7130 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6949 - val_acc: 0.4966 - val_auc_2: 0.5000 - 707ms/epoch - 707ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.6946 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6970 - val_acc: 0.5034 - val_auc_2: 0.5000 - 791ms/epoch - 791ms/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.6976 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7086 - val_acc: 0.5034 - val_auc_2: 0.5000 - 798ms/epoch - 798ms/step\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/5\n",
      "1/1 - 5s - loss: 0.9432 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.8254 - val_acc: 0.5034 - val_auc_2: 0.5000 - 5s/epoch - 5s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.8290 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7447 - val_acc: 0.5034 - val_auc_2: 0.5000 - 805ms/epoch - 805ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.7470 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7031 - val_acc: 0.5034 - val_auc_2: 0.5000 - 988ms/epoch - 988ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.7041 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6936 - val_acc: 0.4966 - val_auc_2: 0.5000 - 985ms/epoch - 985ms/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.6936 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7028 - val_acc: 0.4966 - val_auc_2: 0.5000 - 703ms/epoch - 703ms/step\n",
      "157/157 [==============================] - 2s 10ms/step\n",
      "0.4927337973441224 0.009115793490980859\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "\n",
    "order = 1\n",
    "L, F, Phi = 1, 100, 100\n",
    "print(L, F, Phi, order)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=8)\n",
    "\n",
    "model_name = f\"O{order}_L{L}_2Phi{Phi}_3F{F}\"\n",
    "container = ModelsContainer(**{'Phi_mapping_dim' : [input_dim,L],\n",
    "                            'output_dim' : 2, 'output_act' : 'softmax',\n",
    "                            'Phi_sizes' : [Phi, Phi], 'Phi_acts' : 'ReLU', \"Phi_l1_regs\" :  1e-7,\n",
    "                            'F_sizes' : [F,F,F], 'F_acts': 'ReLU', \"F_l1_regs\" :  1e-7,\n",
    "                            'order' : order , 'architecture_type':'moment',\n",
    "                            'loss': 'binary_crossentropy','metrics': 'acc','metrics': ['acc', tf.keras.metrics.AUC()]})\n",
    "print()\n",
    "print(i, order, container.num_params)\n",
    "print()\n",
    "mean, std = container.train_models(num_models = num_models_to_train,\n",
    "                            X_train = X_train, Y_train = Y_train,\n",
    "                            epochs = 5, batch_size = batch_size,\n",
    "                            path = os.path.join(model_dir , model_name),\n",
    "                            validation_data = (X_val, Y_val),\n",
    "                            callbacks=[callback,], verbose=verbose,\n",
    "                            metric_function = roc_auc_score)\n",
    "# container.test_meanstd(X_test = X_test, Y_test = Y_test, metric_function = roc_auc_score)\n",
    "print(mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
