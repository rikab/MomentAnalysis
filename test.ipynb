{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home01/rikab/MomentAnalysis/energyflow/archs/__init__.py:30: UserWarning: could not import some architectures - cannot import name 'cnn' from partially initialized module 'energyflow.archs' (most likely due to a circular import) (/n/home01/rikab/MomentAnalysis/energyflow/archs/__init__.py)\n",
      "  warnings.warn('could not import some architectures - ' + str(e))\n",
      "/n/home01/rikab/MomentAnalysis/energyflow/archs/__init__.py:40: UserWarning: could not import some architectures - cannot import name 'linear' from partially initialized module 'energyflow.archs' (most likely due to a circular import) (/n/home01/rikab/MomentAnalysis/energyflow/archs/__init__.py)\n",
      "  warnings.warn('could not import some architectures - ' + str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPUs Available:  []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:43:22.875125: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-12 17:43:22.875163: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-12 17:43:22.875189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (boslogin02.rc.fas.harvard.edu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from ModelsContainer import ModelsContainer\n",
    "from numpy import average\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, to_categorical\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import toploader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "train = 2\n",
    "val = 5000\n",
    "test = 5000\n",
    "k_order = 1\n",
    "run_name = \"test\"\n",
    "dataset = \"qg\" # either \"qg\" or \"top\"\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size=512\n",
    "callbacks =None\n",
    "verbose = 2\n",
    "\n",
    "\n",
    "num_models_to_train = 3 ##number of models to use to make error bars\n",
    "order_list = [k_order,] #\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "# Directory Handling\n",
    "base_dir = \"/n/home01/rikab/MomentAnalysis/Data\"\n",
    "run_dir = os.path.join(base_dir, run_name)\n",
    "run_dir = os.path.join(run_dir, f\"order_{k_order}\")\n",
    "model_dir = os.path.join(run_dir, \"Models\")\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "topdir = \"/n/holyscratch01/iaifi_lab/rikab/top\"\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "max_L = 2**(8-k_order)\n",
    "F_width = 25\n",
    "Phi_width = 25\n",
    "\n",
    "\n",
    "Ls = []\n",
    "j = max_L\n",
    "while j >= 1:\n",
    "    Ls.append(j)\n",
    "    j = j / 2\n",
    "\n",
    "num_samples = len(Ls)\n",
    "\n",
    "order_configs = {}\n",
    "for p, order in enumerate(order_list):\n",
    "\n",
    "\n",
    "    configs = []\n",
    "    for i in range(num_samples):\n",
    "        configs.append([Ls[i], F_width, Phi_width])\n",
    "\n",
    "    order_configs['Order %d' % order] = np.asarray(configs).astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"qg\":\n",
    "    X, Y = qg_jets.load(train+val+test, cache_dir=\"/n/holyscratch01/iaifi_lab/rikab/.energyflow\")\n",
    "    X = X[:,:,:3].astype(np.float32)\n",
    "    for x in X:\n",
    "        mask = x[:,0] > 0\n",
    "        yphi_avg = average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "        x[mask,1:3] -= yphi_avg\n",
    "        x[mask,0] /= x[:,0].sum()\n",
    "\n",
    "\n",
    "    Y = to_categorical(Y, num_classes=2)\n",
    "\n",
    "    (z_train, z_val, z_test,\n",
    "    p_train, p_val, p_test,\n",
    "    Y_train, Y_val, Y_test) = data_split(X[:,:,0], X[:,:,1:], Y, val=val, test=test)\n",
    "\n",
    "    X_train = [z_train, p_train]\n",
    "    X_val = [z_val, p_val]\n",
    "    X_test = [z_test, p_test]\n",
    "\n",
    "elif dataset == \"top\":\n",
    "    X_train, Y_train = toploader.load(cache_dir=topdir, dataset=\"train\", num_data = train)\n",
    "    X_test, Y_test = toploader.load(cache_dir=topdir, dataset=\"test\", num_data=test)\n",
    "    X_val, Y_val = toploader.load(cache_dir=topdir, dataset=\"val\", num_data=test)\n",
    "\n",
    "    def format(X):\n",
    "\n",
    "        for x in X:\n",
    "            mask = x[:,0] > 0\n",
    "            yphi_avg = average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "            x[mask,1:3] -= yphi_avg\n",
    "            x[mask,0] /= x[:,0].sum()\n",
    "\n",
    "        return [X[:,:,0], X[:,:,1:3]]\n",
    "    \n",
    "    X_train = format(X_train)\n",
    "    X_test = format(X_test)\n",
    "    X_val = format(X_val)\n",
    "\n",
    "    Y_train = to_categorical(Y_train, num_classes=2)\n",
    "    Y_test = to_categorical(Y_test, num_classes=2)\n",
    "    Y_val = to_categorical(Y_val, num_classes=2)\n",
    "\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"dataset must be either `top` or `qg`!\")\n",
    "\n",
    "\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 100 1\n",
      "\n",
      "7 1 31102\n",
      "\n",
      "Epoch 1/5\n",
      "1/1 - 3s - loss: 0.7523 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7009 - val_acc: 0.5034 - val_auc_2: 0.5000 - 3s/epoch - 3s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.7018 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6952 - val_acc: 0.4966 - val_auc_2: 0.5000 - 714ms/epoch - 714ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.6949 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7075 - val_acc: 0.4966 - val_auc_2: 0.5000 - 713ms/epoch - 713ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.7064 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7133 - val_acc: 0.4966 - val_auc_2: 0.5000 - 1s/epoch - 1s/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.7120 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7097 - val_acc: 0.4966 - val_auc_2: 0.5000 - 1s/epoch - 1s/step\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/5\n",
      "1/1 - 2s - loss: 0.8181 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7566 - val_acc: 0.4966 - val_auc_2: 0.5000 - 2s/epoch - 2s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.7542 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7144 - val_acc: 0.4966 - val_auc_2: 0.5000 - 784ms/epoch - 784ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.7130 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6949 - val_acc: 0.4966 - val_auc_2: 0.5000 - 707ms/epoch - 707ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.6946 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6970 - val_acc: 0.5034 - val_auc_2: 0.5000 - 791ms/epoch - 791ms/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.6976 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7086 - val_acc: 0.5034 - val_auc_2: 0.5000 - 798ms/epoch - 798ms/step\n",
      "157/157 [==============================] - 1s 7ms/step\n",
      "Epoch 1/5\n",
      "1/1 - 5s - loss: 0.9432 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.8254 - val_acc: 0.5034 - val_auc_2: 0.5000 - 5s/epoch - 5s/step\n",
      "Epoch 2/5\n",
      "1/1 - 1s - loss: 0.8290 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7447 - val_acc: 0.5034 - val_auc_2: 0.5000 - 805ms/epoch - 805ms/step\n",
      "Epoch 3/5\n",
      "1/1 - 1s - loss: 0.7470 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7031 - val_acc: 0.5034 - val_auc_2: 0.5000 - 988ms/epoch - 988ms/step\n",
      "Epoch 4/5\n",
      "1/1 - 1s - loss: 0.7041 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.6936 - val_acc: 0.4966 - val_auc_2: 0.5000 - 985ms/epoch - 985ms/step\n",
      "Epoch 5/5\n",
      "1/1 - 1s - loss: 0.6936 - acc: 0.5000 - auc_2: 0.5000 - val_loss: 0.7028 - val_acc: 0.4966 - val_auc_2: 0.5000 - 703ms/epoch - 703ms/step\n",
      "157/157 [==============================] - 2s 10ms/step\n",
      "0.4927337973441224 0.009115793490980859\n"
     ]
    }
   ],
   "source": [
    "## training\n",
    "\n",
    "order = 1\n",
    "L, F, Phi = 1, 100, 100\n",
    "print(L, F, Phi, order)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=8)\n",
    "\n",
    "model_name = f\"O{order}_L{L}_2Phi{Phi}_3F{F}\"\n",
    "container = ModelsContainer(**{'Phi_mapping_dim' : [input_dim,L],\n",
    "                            'output_dim' : 2, 'output_act' : 'softmax',\n",
    "                            'Phi_sizes' : [Phi, Phi], 'Phi_acts' : 'ReLU', \"Phi_l1_regs\" :  1e-7,\n",
    "                            'F_sizes' : [F,F,F], 'F_acts': 'ReLU', \"F_l1_regs\" :  1e-7,\n",
    "                            'order' : order , 'architecture_type':'moment',\n",
    "                            'loss': 'binary_crossentropy','metrics': 'acc','metrics': ['acc', tf.keras.metrics.AUC()]})\n",
    "print()\n",
    "print(i, order, container.num_params)\n",
    "print()\n",
    "mean, std = container.train_models(num_models = num_models_to_train,\n",
    "                            X_train = X_train, Y_train = Y_train,\n",
    "                            epochs = 5, batch_size = batch_size,\n",
    "                            path = os.path.join(model_dir , model_name),\n",
    "                            validation_data = (X_val, Y_val),\n",
    "                            callbacks=[callback,], verbose=verbose,\n",
    "                            metric_function = roc_auc_score)\n",
    "# container.test_meanstd(X_test = X_test, Y_test = Y_test, metric_function = roc_auc_score)\n",
    "print(mean, std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
